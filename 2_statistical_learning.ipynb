{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Statistical Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.\n",
    "- (a) The sample size $n$ is extremely large, and the number of predictors $p$ is small.\n",
    "- (b) The number of predictors $p$ is extremely large, and the number of observations $n$ is small.\n",
    "- (c) The relationship between the predictors and response is highly non-linear.\n",
    "- (d) The variance of the error terms, i.e. $\\sigma^2 = \\mathrm{Var}(\\epsilon)$, is extremely high.\n",
    "\n",
    "### A1\n",
    "\n",
    "In case (a), we would generally expect a flexible method to be better than an inflexible method.\n",
    "With a large number of samples, the flexible method would be less prone to overfitting and would be better able to match the underlying function relating the inputs to the output.\n",
    "\n",
    "In case (b), we would generally expect a flexible method to be worse than an inflexible method.\n",
    "With only a small number of observations, the method would be especially prone to overfitting.\n",
    "\n",
    "In case (c), we would generally expect a flexible method to be better than an inflexible method.\n",
    "The inflexible method would have trouble capturing the curvature in the data, whereas the flexible method would be able to.\n",
    "\n",
    "In case (d), we would generally expect a flexible method to be worse than an inflexible method.\n",
    "The flexible method would be susceptible to following the noise too closely, whereas the inflexible method would still be able to get the gist of the underlying relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide $n$ and $p$.\n",
    "- (a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.\n",
    "- (b) We are considering launching a new product and wish to know whether it will be a *success* or a *failure*. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.\n",
    "- (c) We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.\n",
    "\n",
    "### A2\n",
    "\n",
    "Case (a) is a regression problem where we are most interested in inference.\n",
    "$n = 500, p = 3$\n",
    "\n",
    "Case (b) is a classification problem where we are most interested in prediction.\n",
    "$n = 20, p = 14$\n",
    "\n",
    "Case (c) is a regression problem where we are most interested in prediction.\n",
    "$n = 52, p = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "We now revisit the bias-variance decomposition.\n",
    "- (a) Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.\n",
    "- (b) Explain why each of the five curves has the shape displayed in part (a).\n",
    "\n",
    "### A3\n",
    "\n",
    "- Squared bias\n",
    "    - Decreases as flexibility increases\n",
    "    - A more flexible method can more closely match the underlying function\n",
    "- Variance\n",
    "    - Increases as flexibility increases\n",
    "    - A more flexible method is more sensitive to small changes in the training data set\n",
    "- Training error\n",
    "    - Decreases as flexibility increases\n",
    "    - A more flexible method can more closely match the training data\n",
    "- Test error\n",
    "    - Sum of squared bias, variance, and irreducible error\n",
    "    - U-shaped\n",
    "    - Decreases at first then increases as flexibility increases\n",
    "- Irreducible error\n",
    "    - Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "You will now think of some real-life applications for statistical learning\n",
    "- (a) Describe three real-life applications in which *classification* might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.\n",
    "- (b) Describe three real-life applications in which *regression* might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.\n",
    "- (c) Describe three real-life applications in which *cluster analysis* might be useful.\n",
    "\n",
    "### A4\n",
    "\n",
    "One application of classification is in analyzing the movement of the stock market, predicting whether a particular stock index will increase or decrease on a given day based on the percent changes in the index for the previous 5 or so days.\n",
    "The goal of such an application would be prediction, as determining when the stock price will increase or decrease is more important for making money than the exact reasons for the change.\n",
    "A second application of classification is in determining whether someone is likely to default on a loan.\n",
    "The predictors might include their income, age, credit history, collateral, capital, and conditions of the loan.\n",
    "The goal of such an application would be inference, as banks would likely be interested in knowing which predictors are most significant so that they can prioritize getting that data from clients.\n",
    "A third application of classification is in identifying coins that are rare and valuable.\n",
    "The predictions could be based on the mass of the coin, its diameter, its type, and image data of the front & back sides of the coin.\n",
    "The goal of such an application would be prediction, as once the potential coins of value are set aside, a human can appraise them and confirm their worth and put them up for sale.\n",
    "\n",
    "One application of regression is in determining what factors are most associated with a person's wage.\n",
    "The predictors might include age, education, and the calendar year.\n",
    "The goal of such an application would be inference, as many people would like to know what they can do to increase their wages.\n",
    "For instance, some might wonder if investing in education will lead to higher wages in the future.\n",
    "A second application of regression is in determining what means of advertising lead to the most sales.\n",
    "The predictors could include the advertising budgets for different means such as TV, radio, newspaper, YouTube ads, website ads, and YouTube sponsorships.\n",
    "The goal of such an application would be inference, as a company would want to know which advertising methods are associated with the most sales and which ones they should devote the most money towards.\n",
    "A third application of regression is in determining the values of homes.\n",
    "The predictors could include the crime rate, zoning, distance from a river, air quality, schools, income level of the community, size of the houses, and so on.\n",
    "The goal of such an application could be prediction if all a real estate agent cared about was setting a price, or a client determining if the price for a house is reasonable.\n",
    "The goal might also be inference if they wanted to explain to a client the reason for the pricing.\n",
    "\n",
    "One application of cluster analysis is in a market segmentation study.\n",
    "Based on characteristics for potential customers such as zip code, family income, and shopping habits, a firm might want to identify distinct groups of customers.\n",
    "This can possibly help the company find ways to target those groups.\n",
    "A second application of cluster analysis is in analyzing gene expression data for cancer cell lines.\n",
    "The goal would be to identify groups among the different cell lines, as that information could potentially help with treatment.\n",
    "A third application of cluster analysis is in image analysis, helping identify groups of related pixels that represent an object.\n",
    "For instance, it might help with identifying letters or faces in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?\n",
    "\n",
    "### A5\n",
    "\n",
    "A very flexible approach allows for greater variety in the functions generated, thus giving it the potential to describe more complex underlying relationships.\n",
    "However, if there is not enough training data, a very flexible approach could be susceptible to overfitting, picking up on patterns that are caused by random variation rather than properties of the underlying function.\n",
    "A very flexible approach would also be prone to overfitting if the irreducible error in the data is high, following the noise too closely.\n",
    "A less flexible approach might be preferred if there is not much training data or there is lots of irreducible error.\n",
    "It would still be able to get the gist of the underlying relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "\n",
    "Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a non-parametric approach)? What are its disadvantages?\n",
    "\n",
    "### A6\n",
    "\n",
    "Parametric approaches make an assumption about the functional form of the underlying relationship.\n",
    "That function has coefficients/parameters that can be tuned to produce different shapes based on the training data.\n",
    "Non-parametric approaches make no assumptions about the functional form, and instead try to match the data as closely as possible without being too rough or wiggly.\n",
    "It is generally much easier to estimate a set of parameters than an entirely arbitrary function.\n",
    "But, there are no guarantees that the model chosen matches the form of the underlying function, and it could potentially be very different.\n",
    "Non-parametric methods can fit a wider range of possible function shapes without making any assumptions about the underlying form, but they often require a very large number of observations in order to obtain an accurate estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7\n",
    "\n",
    "The table below provides a training data set containing six observations, three predictors, and one qualitative response variable. Suppose we wish to use this data set to make a prediction for $Y$ when $X_1 = X_2 = X_3 = 0$ using $K$-nearest neighbors.\n",
    "    - (a) Compute the Euclidean distance between each observation and the test point, $X_1 = X_2 = X_3 = 0$.\n",
    "    - (b) What is our prediction with $K = 1$? Why?\n",
    "    - (c) What is our prediction with $K = 3$? Why?\n",
    "    - (d) If the Bayes decision boundary in this problem is highly non-linear, then would we expect the *best* value for $K$ to be large or small? Why?\n",
    "\n",
    "| Obs. | $X_1$ | $X_2$ | $X_3$ | $Y$   |\n",
    "| ---- | ----- | ----- | ----- | ----- |\n",
    "| 1    |  0    |  3    |  0    | Red   |\n",
    "| 2    |  2    |  0    |  0    | Red   |\n",
    "| 3    |  0    |  1    |  3    | Red   |\n",
    "| 4    |  0    |  1    |  2    | Green |\n",
    "| 5    | -1    |  0    |  1    | Green |\n",
    "| 6    |  1    |  1    |  1    | Red   |\n",
    "\n",
    "### A7\n",
    "\n",
    "If the Bayes decision boundary is highly non-linear, then we would expect the *best* value for $K$ to be small.\n",
    "Large $K$ values tend to produce more linear boundaries, while low $K$ values tend to produce more wiggly boundaries.\n",
    "With a small $K$ the model is more flexible, using only the most nearby observations for its decision.\n",
    "With a large $K$ the model is less flexible, using a larger portion of the observations for its decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X_1  X_2  X_3      Y  Distance\n",
      "1    0    3    0    Red  3.000000\n",
      "2    2    0    0    Red  2.000000\n",
      "3    0    1    3    Red  3.162278\n",
      "4    0    1    2  Green  2.236068\n",
      "5    1    0    1  Green  1.414214\n",
      "6    1    1    1    Red  1.732051\n",
      "\n",
      "K = 1, Green\n",
      "\n",
      "K = 3, Red\n"
     ]
    }
   ],
   "source": [
    "# Create some helper function\n",
    "def distance(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidian distance between two points, a and b.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "def K_nearest_neighbors(df, predictor_cols, response_col, test_point, K):\n",
    "    \"\"\"\n",
    "    Use K-nearest neighbors on the data in the dataframe, 'df'.\n",
    "    'predictors_cols' are the names of the predictor columuns.\n",
    "    'respones_col' is the name of the response column.\n",
    "    'test_point' is an array with the test point.\n",
    "    'K' is the K value, how many of the closest points to consider.\n",
    "    \"\"\"\n",
    "    return (df\n",
    "        .assign(Distance=lambda df_: df_.loc[:,predictor_cols].apply(lambda x: distance(x, test_point), axis=\"columns\", raw=True))\n",
    "        .nsmallest(K, \"Distance\")\n",
    "        .loc[:,response_col]\n",
    "        .mode()\n",
    "        .iloc[0]\n",
    "    )\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = [\n",
    "    [0, 3, 0, \"Red\"],\n",
    "    [2, 0, 0, \"Red\"],\n",
    "    [0, 1, 3, \"Red\"],\n",
    "    [0, 1, 2, \"Green\"],\n",
    "    [1, 0, 1, \"Green\"],\n",
    "    [1, 1, 1, \"Red\"],\n",
    "]\n",
    "df = pd.DataFrame(data,\n",
    "    columns=[\"X_1\", \"X_2\", \"X_3\", \"Y\"],\n",
    "    index=range(1, len(data) + 1),\n",
    ")\n",
    "\n",
    "# Compute the Euclidian distance between each observation and the test point\n",
    "test_point = np.array([0, 0, 0])\n",
    "df[\"Distance\"] = df.loc[:,\"X_1\":\"X_3\"].apply(lambda x: distance(x, test_point), axis=\"columns\", raw=True)\n",
    "print(df)\n",
    "\n",
    "# Make a prediction with K = 1, then K = 3\n",
    "for K in [1, 3]:\n",
    "    prediction = K_nearest_neighbors(df, [\"X_1\", \"X_2\", \"X_3\"], \"Y\", test_point, K)\n",
    "    print()\n",
    "    print(f\"K = {K}, {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
